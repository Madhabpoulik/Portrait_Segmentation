{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "import scipy\n",
    "import cv2\n",
    "import dlib\n",
    "#sys.path.append('/Users/yu-chieh/seg_models/models/slim/')\n",
    "#sys.path.append(\"/Users/yu-chieh/seg_models/tf-image-segmentation/\")\n",
    "#from tf_image_segmentation.models.fcn_8s import FCN_8s\n",
    "#from tf_image_segmentation.utils.inference import adapt_network_for_any_size_input\n",
    "from scipy import misc\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function that returns certain no of images as numpy arrays for further preprocessing\n",
    "def get_all_images_for_fcn(num_images, path):\n",
    "    # get num_images images form the path and put as a matrix\n",
    "    imgs = []\n",
    "    num = 0\n",
    "    for f in os.listdir(path): #iterating on all the files in the directory\n",
    "        print(f)\n",
    "        if num >= num_images:\n",
    "            return np.array(imgs)\n",
    "        image_path = os.path.join(path,f)\n",
    "        image = scipy.ndimage.imread(image_path, mode='RGB') #reading images in RGB mode\n",
    "        # cheating version\n",
    "        # image = np.dstack((image, get_xy_mask(image)))\n",
    "        imgs.append(image)  #storing the images as numpy array\n",
    "        num += 1\n",
    "    return np.array(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now our main job is to detect the face or important feature points of the face in the image and apply a homography transform to project the face on another co-ordinate plane in such a way that the transformed image is centered around the face and the label of every pixel is detected calculating the distance between the origin(face) and that pixel. By this channel we can centralize the face in the image that gives us better segmentation result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function detecting facial point\n",
    "#this function takes a image as a input and retruns the co-ordinates of the main facial feature points\n",
    "\n",
    "def get_facial_points(image, num_points):\n",
    "    predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
    "    detector = dlib.get_frontal_face_detector() #creats a face detector object\n",
    "    dets = detector(image, 1)\n",
    "    win = dlib.image_window()\n",
    "    win.clear_overlay()\n",
    "    win.set_image(image)\n",
    "    points = []\n",
    "    for k, d in enumerate(dets):\n",
    "        # Get the landmarks/parts for the face in box d.\n",
    "        shape = predictor(image, d)\n",
    "        for i in range(num_points):\n",
    "            pt = shape.part(i)\n",
    "            points.append([int(pt.x), int(pt.y)])\n",
    "        win.add_overlay(shape)\n",
    "    win.add_overlay(dets)\n",
    "    dlib.hit_enter_to_continue()\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='C:/Users/hp/Desktop/ML Projects/Portrait Segmentation/dataset/training/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Normalized x-y channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_mask(img_path,mask_path):\n",
    "    image_src = scipy.ndimage.imread(img_path,mode = 'RGB')\n",
    "    mask_dst = scipy.ndimage.imread(mask_path, mode = 'RGB')\n",
    "    dst = get_facial_points(mask_dst, 68)\n",
    "    src = get_facial_points(image_src, 68)\n",
    "    h, status = cv2.findHomography(src, dst)\n",
    "    im_dst = cv2.warpPerspective(image_src, h, (image_src.shape[1], image_src.shape[0]))\n",
    "    return im_dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for reducing the dimensionality keeping most of it's variant intact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import PCA as RandomizedPCA\n",
    "def apply_PCA(image):\n",
    "    pca = RandomizedPCA(200)\n",
    "    pca.fit(image)\n",
    "    components = pca.transform(image)\n",
    "    projected = pca.inverse_transform(components)\n",
    "    projected = projected.flatten().reshape(3,800,400)\n",
    "    trans_image = projected\n",
    "    return trans_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
